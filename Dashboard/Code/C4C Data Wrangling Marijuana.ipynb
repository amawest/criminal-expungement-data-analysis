{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a096aac8",
   "metadata": {},
   "source": [
    "# Data Wrangling Criminal Expungement Dashboard Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e163806",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "116ee9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n/usr/libexec/java_home -V\\nexport JAVA_HOME=/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\\nexport PATH=$JAVA_HOME/bin:$PATH\\nwhich java\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STOP!\n",
    "# Before you do anything, copy the code below. You'll need to shut down the \n",
    "# notebook, close and re-open the terminal and paste this code in *before* you call jupyter notebook.\n",
    "# We need to switch to Java 8 before we can load PySpark functions. \n",
    "'''\n",
    "/usr/libexec/java_home -V\n",
    "export JAVA_HOME=/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\n",
    "export PATH=$JAVA_HOME/bin:$PATH\n",
    "which java\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b2af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a24beace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/Users/amawest/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15bf11c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_292\"\r\n",
      "OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_292-b10)\r\n",
      "OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.292-b10, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faaacc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all the raw data from Virginia Open Court Data\n",
    "data_2010 = pd.read_csv('circuit_data/circuit_criminal_2010_anon_00.csv')\n",
    "data_2011 = pd.read_csv('circuit_data/circuit_criminal_2011_anon_00.csv')\n",
    "data_2012 = pd.read_csv('circuit_data/circuit_criminal_2012_anon_00.csv')\n",
    "data_2013 = pd.read_csv('circuit_data/circuit_criminal_2013_anon_00.csv')\n",
    "data_2014 = pd.read_csv('circuit_data/circuit_criminal_2014_anon_00.csv')\n",
    "data_2015 = pd.read_csv('circuit_data/circuit_criminal_2015_anon_00.csv')\n",
    "data_2016 = pd.read_csv('circuit_data/circuit_criminal_2016_anon_00.csv')\n",
    "data_2017 = pd.read_csv('circuit_data/circuit_criminal_2017_anon_00.csv')\n",
    "data_2018 = pd.read_csv('circuit_data/circuit_criminal_2018_anon_00.csv')\n",
    "data_2019 = pd.read_csv('circuit_data/circuit_criminal_2019_anon_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af764c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder so that all dataframes are organzed by \"OffenseDate\" (when the offense was supposedly committed)\n",
    "data_2010['OffenseDate'] = pd.to_datetime(data_2010['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2010 = data_2010.sort_values(by=['OffenseDate'])\n",
    "data_2010.to_csv('circuit_data/circuit_criminal_2010_anon_00.csv')\n",
    "\n",
    "data_2011['OffenseDate'] = pd.to_datetime(data_2011['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2011 = data_2011.sort_values(by=['OffenseDate'])\n",
    "data_2011.to_csv('circuit_data/circuit_criminal_2011_anon_00.csv')\n",
    "\n",
    "data_2012['OffenseDate'] = pd.to_datetime(data_2012['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2012 = data_2012.sort_values(by=['OffenseDate'])\n",
    "data_2012.to_csv('circuit_data/circuit_criminal_2012_anon_00.csv')\n",
    "\n",
    "data_2013['OffenseDate'] = pd.to_datetime(data_2013['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2013 = data_2013.sort_values(by=['OffenseDate'])\n",
    "data_2013.to_csv('circuit_data/circuit_criminal_2013_anon_00.csv')\n",
    "\n",
    "data_2014['OffenseDate'] = pd.to_datetime(data_2014['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2014 = data_2014.sort_values(by=['OffenseDate'])\n",
    "data_2014.to_csv('circuit_data/circuit_criminal_2014_anon_00.csv')\n",
    "\n",
    "data_2015['OffenseDate'] = pd.to_datetime(data_2015['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2015 = data_2015.sort_values(by=['OffenseDate'])\n",
    "data_2015.to_csv('circuit_data/circuit_criminal_2015_anon_00.csv')\n",
    "\n",
    "data_2016['OffenseDate'] = pd.to_datetime(data_2016['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2016 = data_2016.sort_values(by=['OffenseDate'])\n",
    "data_2016.to_csv('circuit_data/circuit_criminal_2016_anon_00.csv')\n",
    "\n",
    "data_2017['OffenseDate'] = pd.to_datetime(data_2017['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2017 = data_2017.sort_values(by=['OffenseDate'])\n",
    "data_2017.to_csv('circuit_data/circuit_criminal_2017_anon_00.csv')\n",
    "\n",
    "data_2018['OffenseDate'] = pd.to_datetime(data_2018['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2018 = data_2018.sort_values(by=['OffenseDate'])\n",
    "data_2018.to_csv('circuit_data/circuit_criminal_2018_anon_00.csv')\n",
    "\n",
    "data_2019['OffenseDate'] = pd.to_datetime(data_2019['OffenseDate'], format='%Y-%m-%d', errors='ignore')\n",
    "data_2019 = data_2019.sort_values(by=['OffenseDate'])\n",
    "data_2019.to_csv('circuit_data/circuit_criminal_2019_anon_00.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36944b7c",
   "metadata": {},
   "source": [
    "## Part 2: Match Counties to Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1cfcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20108</td>\n",
       "      <td>Manassas city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20110</td>\n",
       "      <td>Manassas city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20113</td>\n",
       "      <td>Manassas Park city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22030</td>\n",
       "      <td>Fairfax city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22038</td>\n",
       "      <td>Fairfax city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>26855</td>\n",
       "      <td>Grant County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>26865</td>\n",
       "      <td>Hampshire County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>26866</td>\n",
       "      <td>Pendleton County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>26884</td>\n",
       "      <td>Pendleton County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>26886</td>\n",
       "      <td>Pendleton County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2099 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Zip Code              County\n",
       "0        20108       Manassas city\n",
       "1        20110       Manassas city\n",
       "2        20113  Manassas Park city\n",
       "3        22030        Fairfax city\n",
       "4        22038        Fairfax city\n",
       "...        ...                 ...\n",
       "2094     26855        Grant County\n",
       "2095     26865    Hampshire County\n",
       "2096     26866    Pendleton County\n",
       "2097     26884    Pendleton County\n",
       "2098     26886    Pendleton County\n",
       "\n",
       "[2099 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_county_zips = pd.read_csv('county_zip_edited.csv')\n",
    "correct_county_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fff8dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amawest/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (5,27,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/Users/amawest/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (39,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# split out zipcodes in the file and make sure every thing is correctly in the state of Virginia\n",
    "for i in range(0,10):\n",
    "    file = pd.read_csv(f'circuit_data/circuit_criminal_201{i}_anon_00.csv')\n",
    "    file[['city_state', 'Zip Code']] = file.Address.str.rsplit(\" \", n=1, expand=True,)\n",
    "    file = file[file['city_state'].notnull()]\n",
    "    file = file[file['city_state'].str.contains('VA')]\n",
    "    #file_zips = file_zips[~file_zips['Zip Code'].str.contains('-')]\n",
    "    #file_zips = file_zips[file_zips['Zip Code'].str.contains('(?<!\\n)[\\d]{5,6}[\\-]?[\\d]*')]\n",
    "    #file['state']  = 'Virginia'\n",
    "    correct_county_zips['Zip Code'] = correct_county_zips['Zip Code'].astype(str)\n",
    "    file['Zip Code'] = file['Zip Code'].astype(str)\n",
    "    file = pd.merge(file, correct_county_zips, how='left', on='Zip Code')\n",
    "    file.to_csv(f'circuit_data/zips_circuit_criminal_201{i}_anon_00.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7ad85",
   "metadata": {},
   "source": [
    "## Part 3: Aggregate Data from Individuals --> % of Various Populations\n",
    "- The FIPS covered less than counties, so I'd like to try counties and see how much coverage we see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f775d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('circuit_data/zips_circuit_criminal_2010_anon_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f6f87e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_2010.fips.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c3604c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.County.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcc12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "# note that we only keep DISTINCT (i.e. unique) person IDs from here on out\n",
    "for i in range(0,10):\n",
    "    infile = (f'circuit_data/zips_circuit_criminal_201{i}_anon_00.csv')\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Racial Disparity\") \\\n",
    "        .getOrCreate()\n",
    "    circuit = spark.read.csv(infile, inferSchema = True, header = True)\n",
    "    circuit.createOrReplaceTempView(\"data\")\n",
    "    sqlDF = spark.sql(\n",
    "        \n",
    "        # currently set to look at marijuana code sections only\n",
    "        # but just take out code sections to see everything (or add more code sections)\n",
    "        '''\n",
    "        SELECT COUNT(DISTINCT(person_id)) as Count, Race, Sex, County FROM data\n",
    "                   WHERE (CodeSection LIKE '18.2-248%' \n",
    "                   OR CodeSection LIKE '18.2-250%'\n",
    "                   OR CodeSection LIKE '18.2-255%')\n",
    "                   GROUP BY Race, County, Sex\n",
    "                   ORDER BY Count DESC\n",
    "                   '''\n",
    "    )\n",
    "    data = sqlDF.toPandas()\n",
    "    data['Race and Sex'] = data['Race'] + ' - ' + data['Sex']\n",
    "    data = data[['County', 'Race and Sex', 'Count']]\n",
    "    df_p = data.pivot_table(index=['County'], columns=['Race and Sex'], values='Count', aggfunc=np.sum)\n",
    "    data_1 = df_p.fillna(0)\n",
    "    data_1.to_csv(f'circuit_data/201{i}_finished.csv')\n",
    "\n",
    "# ================\n",
    "# NOTE: Add/remove as desired to change the type of query\n",
    "# Marijuana\n",
    "# WHERE (CodeSection LIKE '18.2-248%' \n",
    "# OR CodeSection LIKE '18.2-250%'\n",
    "# OR CodeSection LIKE '18.2-255%')\n",
    "\n",
    "# Felonys\n",
    "# AND (ChargeType == 'Felony')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b18fab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code to rename 2019 to match 2010-2018 column labels (currently not using)\n",
    "x = pd.read_csv('circuit_data/2019_finished.csv')\n",
    "new_cols = {'American Indian Or Alaskan Native - Female':         'American Indian - Female',\n",
    "            'American Indian Or Alaskan Native - Male':           'American Indian - Male',\n",
    "            'Asian Or Pacific Islander - Female':                 'Asian Or Pacific Islander - Female',\n",
    "            'Asian Or Pacific Islander - Male':                   'Asian Or Pacific Islander - Male',\n",
    "            'Black - Female':                                     'Black (Non-Hispanic) - Female',\n",
    "            'Black - Male':                                       'Black (Non-Hispanic) - Male',\n",
    "            'Hispanic - Female':                                  'Hispanic - Female',\n",
    "            'Hispanic - Male':                                    'Hispanic - Male',\n",
    "            'White - Female':                                     'White Caucasian (Non-Hispanic) - Female',\n",
    "            'White - Male':                                       'White Caucasian (Non-Hispanic) - Male',\n",
    "            'Other (Includes Not Applicable, Unknown) - Female':  'Other (Includes Not Applicable, Unknown) - Female',\n",
    "            'Other (Includes Not Applicable, Unknown) - Male':    'Other (Includes Not Applicable, Unknown) - Male',\n",
    "           }\n",
    "x.rename(columns=new_cols,\n",
    "          inplace=True)\n",
    "x.to_csv('circuit_data/2019_finished.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17c5a177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(infile).CTYNAME.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e2eec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    # Note: make sure to reset the year each time\n",
    "    infile = 'census_data_fips.csv'\n",
    "    spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Census Data\") \\\n",
    "    .getOrCreate()\n",
    "    circuit = spark.read.csv(infile, inferSchema=True, header = True)\n",
    "    circuit.createOrReplaceTempView(\"census_data\")\n",
    "    sqlDF = spark.sql(f'SELECT * \\\n",
    "                   FROM census_data \\\n",
    "                   WHERE Year = 201{i}')\n",
    "    census = sqlDF.toPandas()\n",
    "    \n",
    "    #--------------------#\n",
    "    data = pd.read_csv(f'circuit_data/201{i}_finished.csv')\n",
    "    #--------------------#\n",
    "    data['Total_Crimes'] = 0\n",
    "    data['Total_Crimes'] = data.sum(axis=1) \n",
    "    data.head(2)\n",
    "    #del census['Year']\n",
    "    census.head(2)\n",
    "    result = pd.merge(census,\n",
    "                  data,\n",
    "                  left_on = 'CTYNAME',\n",
    "                  right_on= 'County', \n",
    "                  how='left')\n",
    "    result.head(2)\n",
    "    data.columns\n",
    "    result['Percent_Overall']          = (result['Total_Crimes']   / result['Total'])*100\n",
    "    result['Percent_White_Male']       = (result['White Caucasian (Non-Hispanic) - Male']   / result['White_Male'])*100\n",
    "    result['Percent_White_Female']     = (result['White Caucasian (Non-Hispanic) - Female'] / result['White_Female'])*100\n",
    "    result['Percent_Black_Male']       = (result['Black (Non-Hispanic) - Male']             / result['Black_Male'])*100\n",
    "    result['Percent_Black_Female']     = (result['Black (Non-Hispanic) - Female']           / result['Black_Female'])*100\n",
    "    #result['Percent_Nat_Amer_Male']    = (result['American Indian - Male']                  / result['Native_Amer_Male'])*100\n",
    "    #result['Percent_Nat_Amer_Female']  = (result['American Indian - Female']                / result['Native_Amer_Female'])*100\n",
    "    result['Percent_Hispanic_Male']    = (result['Hispanic - Male']                         / result['Hispanic_Male'])*100\n",
    "    result['Percent_Hispanic_Female']  = (result['Hispanic - Female']                       / result['Hispanic_Female'])*100\n",
    "    result['Percent_Asian_Pac_Male']   = (result['Asian Or Pacific Islander - Male']        / result['Asian_Male'])*100\n",
    "    result['Percent_Asian_Pac_Female'] = (result['Asian Or Pacific Islander - Female']      / result['Asian_Female'])*100\n",
    "    \n",
    "    result['Percent_Overall']            = round(result['Percent_Overall'],3)\n",
    "    result['Disparity_White_Male']       = round(result['Percent_White_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_White_Female']     = round(result['Percent_White_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Black_Male']       = round(result['Percent_Black_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Black_Female']     = round(result['Percent_Black_Female'] - result['Percent_Overall'],3)\n",
    "    #result['Disparity_Nat_Amer_Male']    = round(result['Percent_Nat_Amer_Male'] - result['Percent_Overall'],3)\n",
    "    #result['Disparity_Nat_Amer_Female']  = round(result['Percent_Nat_Amer_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Hispanic_Male']    = round(result['Percent_Hispanic_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Hispanic_Female']  = round(result['Percent_Hispanic_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Asian_Pac_Male']   = round(result['Percent_Asian_Pac_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Asian_Pac_Female'] = round(result['Percent_Asian_Pac_Female'] - result['Percent_Overall'],3)\n",
    "    \n",
    "    result = result[['fips', \n",
    "                     'CTYNAME',\n",
    "                     'Percent_Overall',\n",
    "                     'Disparity_White_Male',\n",
    "                     'Disparity_White_Female',\n",
    "                     'Disparity_Black_Male',\n",
    "                     'Disparity_Black_Female', \n",
    "                     #'Disparity_Nat_Amer_Male',\n",
    "                     #'Disparity_Nat_Amer_Female', \n",
    "                     'Disparity_Hispanic_Male',\n",
    "                     'Disparity_Hispanic_Female',\n",
    "                     'Disparity_Asian_Pac_Male',\n",
    "                     'Disparity_Asian_Pac_Female'\n",
    "        ]]\n",
    "    result\n",
    "    #--------------------#\n",
    "    result.to_csv(f'circuit_data/Final/201{i}_disparities.csv',index=None)\n",
    "    #--------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebe9e6",
   "metadata": {},
   "source": [
    "## Part 4: Put It All Together & Finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76276714",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2010 = pd.read_csv('circuit_data/Final/2010_disparities.csv')\n",
    "x_2011 = pd.read_csv('circuit_data/Final/2011_disparities.csv')\n",
    "x_2012 = pd.read_csv('circuit_data/Final/2012_disparities.csv')\n",
    "x_2013 = pd.read_csv('circuit_data/Final/2013_disparities.csv')\n",
    "x_2014 = pd.read_csv('circuit_data/Final/2014_disparities.csv')\n",
    "x_2015 = pd.read_csv('circuit_data/Final/2015_disparities.csv')\n",
    "x_2016 = pd.read_csv('circuit_data/Final/2016_disparities.csv')\n",
    "x_2017 = pd.read_csv('circuit_data/Final/2017_disparities.csv')\n",
    "x_2018 = pd.read_csv('circuit_data/Final/2018_disparities.csv')\n",
    "x_2019 = pd.read_csv('circuit_data/Final/2019_disparities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6fee3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2010['year'] = 2010\n",
    "x_2011['year'] = 2011\n",
    "x_2012['year'] = 2012\n",
    "x_2013['year'] = 2013\n",
    "x_2014['year'] = 2014\n",
    "x_2015['year'] = 2015\n",
    "x_2016['year'] = 2016\n",
    "x_2017['year'] = 2017\n",
    "x_2018['year'] = 2018\n",
    "x_2019['year'] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5c7cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2010.to_csv('circuit_data/Final/2010_disparities.csv')\n",
    "x_2011.to_csv('circuit_data/Final/2011_disparities.csv')\n",
    "x_2012.to_csv('circuit_data/Final/2012_disparities.csv')\n",
    "x_2013.to_csv('circuit_data/Final/2013_disparities.csv')\n",
    "x_2014.to_csv('circuit_data/Final/2014_disparities.csv')\n",
    "x_2015.to_csv('circuit_data/Final/2015_disparities.csv')\n",
    "x_2016.to_csv('circuit_data/Final/2016_disparities.csv')\n",
    "x_2017.to_csv('circuit_data/Final/2017_disparities.csv')\n",
    "x_2018.to_csv('circuit_data/Final/2018_disparities.csv')\n",
    "x_2019.to_csv('circuit_data/Final/2019_disparities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "412d2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['circuit_data/Final/2010_disparities.csv',\n",
    "         'circuit_data/Final/2011_disparities.csv',\n",
    "         'circuit_data/Final/2012_disparities.csv',\n",
    "         'circuit_data/Final/2013_disparities.csv',\n",
    "         'circuit_data/Final/2014_disparities.csv',\n",
    "         'circuit_data/Final/2015_disparities.csv',\n",
    "         'circuit_data/Final/2016_disparities.csv',\n",
    "         'circuit_data/Final/2017_disparities.csv',\n",
    "         'circuit_data/Final/2018_disparities.csv',\n",
    "         'circuit_data/Final/2019_disparities.csv'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23eded93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(f, sep=\",\") for f in files]\n",
    "all_files = pd.concat(dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f86cbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_files['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d029932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>Percent_Overall</th>\n",
       "      <th>Disparity_White_Male</th>\n",
       "      <th>Disparity_White_Female</th>\n",
       "      <th>Disparity_Black_Male</th>\n",
       "      <th>Disparity_Black_Female</th>\n",
       "      <th>Disparity_Nat_Amer_Male</th>\n",
       "      <th>Disparity_Hispanic_Male</th>\n",
       "      <th>Disparity_Hispanic_Female</th>\n",
       "      <th>Disparity_Asian_Pac_Male</th>\n",
       "      <th>Disparity_Asian_Pac_Female</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Accomack County</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Albemarle County</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Alleghany County</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>1.637</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Amelia County</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.671</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Amherst County</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>800</td>\n",
       "      <td>Suffolk city</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>810</td>\n",
       "      <td>Virginia Beach city</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>820</td>\n",
       "      <td>Waynesboro city</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>2.033</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>830</td>\n",
       "      <td>Williamsburg city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>840</td>\n",
       "      <td>Winchester city</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>1.783</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fips              CTYNAME  Percent_Overall  Disparity_White_Male  \\\n",
       "0        1      Accomack County            0.139                -0.042   \n",
       "1        3     Albemarle County            0.057                 0.004   \n",
       "2        5     Alleghany County            0.191                 0.052   \n",
       "3        7        Amelia County            0.212                 0.019   \n",
       "4        9       Amherst County            0.173                 0.028   \n",
       "...    ...                  ...              ...                   ...   \n",
       "1325   800         Suffolk city            0.150                -0.030   \n",
       "1326   810  Virginia Beach city            0.144                 0.037   \n",
       "1327   820      Waynesboro city            0.751                 0.001   \n",
       "1328   830    Williamsburg city              NaN                   NaN   \n",
       "1329   840      Winchester city            0.545                 0.028   \n",
       "\n",
       "      Disparity_White_Female  Disparity_Black_Male  Disparity_Black_Female  \\\n",
       "0                     -0.130                 0.483                  -0.000   \n",
       "1                     -0.048                 0.390                   0.021   \n",
       "2                     -0.139                 1.637                   0.347   \n",
       "3                     -0.128                 0.671                  -0.212   \n",
       "4                     -0.112                 0.588                  -0.141   \n",
       "...                      ...                   ...                     ...   \n",
       "1325                  -0.100                 0.315                  -0.102   \n",
       "1326                  -0.065                 0.343                  -0.070   \n",
       "1327                  -0.150                 2.033                  -0.377   \n",
       "1328                     NaN                   NaN                     NaN   \n",
       "1329                  -0.203                 1.783                  -0.221   \n",
       "\n",
       "      Disparity_Nat_Amer_Male  Disparity_Hispanic_Male  \\\n",
       "0                      -0.139                   -0.139   \n",
       "1                      -0.057                    0.080   \n",
       "2                      -0.191                   -0.191   \n",
       "3                      -0.212                   -0.212   \n",
       "4                      -0.173                   -0.173   \n",
       "...                       ...                      ...   \n",
       "1325                   -0.150                   -0.150   \n",
       "1326                   -0.144                   -0.144   \n",
       "1327                   -0.751                   -0.649   \n",
       "1328                      NaN                      NaN   \n",
       "1329                   -0.545                   -0.360   \n",
       "\n",
       "      Disparity_Hispanic_Female  Disparity_Asian_Pac_Male  \\\n",
       "0                        -0.139                    -0.139   \n",
       "1                        -0.057                    -0.057   \n",
       "2                        -0.191                    -0.191   \n",
       "3                        -0.212                    -0.212   \n",
       "4                        -0.173                    -0.173   \n",
       "...                         ...                       ...   \n",
       "1325                     -0.150                    -0.024   \n",
       "1326                     -0.144                    -0.144   \n",
       "1327                     -0.751                    -0.751   \n",
       "1328                        NaN                       NaN   \n",
       "1329                     -0.545                    -0.545   \n",
       "\n",
       "      Disparity_Asian_Pac_Female  year  \n",
       "0                         -0.139  2010  \n",
       "1                         -0.057  2010  \n",
       "2                         -0.191  2010  \n",
       "3                         -0.212  2010  \n",
       "4                         -0.173  2010  \n",
       "...                          ...   ...  \n",
       "1325                      -0.150  2019  \n",
       "1326                      -0.133  2019  \n",
       "1327                      -0.751  2019  \n",
       "1328                         NaN  2019  \n",
       "1329                      -0.291  2019  \n",
       "\n",
       "[1330 rows x 13 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af42b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files.to_csv('marijuana_disparities_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f91a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
